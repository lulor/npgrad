{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import npgrad as npg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_CLASSES = 10\n",
    "H = W = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpgNet(npg.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        from npgrad import nn\n",
    "\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5, 2, 2, 1, bias=False)\n",
    "        self.pool1 = nn.AvgPool2d(2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5, 2, 2, 1, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(4, padding=2)\n",
    "        self.linear1 = nn.Linear(144, 64, bias=False)\n",
    "        self.linear2 = nn.Linear(64, N_CLASSES, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.reshape((len(x), -1))\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TorchNet(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        from torch import nn\n",
    "\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5, 2, 2, 1, bias=False)\n",
    "        self.pool1 = nn.AvgPool2d(2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5, 2, 2, 1, bias=False)\n",
    "        self.pool2 = nn.MaxPool2d(4, padding=2)\n",
    "        self.linear1 = nn.Linear(144, 64, bias=False)\n",
    "        self.linear2 = nn.Linear(64, N_CLASSES, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.reshape((len(x), -1))\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights(weights: tuple[tuple[npg.Array, torch.Tensor], ...]) -> None:\n",
    "    for a, t in weights:\n",
    "        data = np.array(t.detach().numpy())\n",
    "        a.data = data if len(a) == len(data) else data.T\n",
    "\n",
    "\n",
    "def compute_npg(data: np.ndarray, lbls: np.ndarray, model: NpgNet) -> npg.Array:\n",
    "    out = model(data)\n",
    "    loss = npg.nn.functional.cross_entropy(out, lbls).mean()\n",
    "    loss.backward()\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_torch(data: np.ndarray, lbls: np.ndarray, model: TorchNet) -> torch.Tensor:\n",
    "    out = model(torch.from_numpy(data))\n",
    "    loss = torch.nn.functional.cross_entropy(out, torch.from_numpy(lbls))\n",
    "    loss.backward()\n",
    "    return out\n",
    "\n",
    "\n",
    "def max_diff(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = a if a.shape == b.shape else a.T\n",
    "    assert a.shape == b.shape\n",
    "    return np.max(np.abs(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 20:\n",
      "Max out diff: 6.05359673500061e-09\n",
      "Max weights data diff: 1.4901161193847656e-08\n",
      "Max weights grad diff: 1.3969838619232178e-08\n",
      "\n",
      "Step 40:\n",
      "Max out diff: 8.381903171539307e-09\n",
      "Max weights data diff: 1.4901161193847656e-08\n",
      "Max weights grad diff: 2.1886080503463745e-08\n",
      "\n",
      "Step 60:\n",
      "Max out diff: 6.984919309616089e-09\n",
      "Max weights data diff: 1.4901161193847656e-08\n",
      "Max weights grad diff: 1.862645149230957e-08\n",
      "\n",
      "Step 80:\n",
      "Max out diff: 5.587935447692871e-09\n",
      "Max weights data diff: 2.2351741790771484e-08\n",
      "Max weights grad diff: 2.3283064365386963e-08\n",
      "\n",
      "Step 100:\n",
      "Max out diff: 7.916241884231567e-09\n",
      "Max weights data diff: 2.2351741790771484e-08\n",
      "Max weights grad diff: 4.0978193283081055e-08\n"
     ]
    }
   ],
   "source": [
    "data = np.random.rand(BATCH_SIZE, 3, H, W).astype(np.float32)\n",
    "lbls = np.random.randint(0, N_CLASSES, BATCH_SIZE)\n",
    "\n",
    "npg_model = NpgNet()\n",
    "torch_model = TorchNet()\n",
    "models = npg_model, torch_model\n",
    "weights = (\n",
    "    tuple(m.conv1.weight for m in models),\n",
    "    tuple(m.conv2.weight for m in models),\n",
    "    tuple(m.linear1.weight for m in models),\n",
    "    tuple(m.linear2.weight for m in models),\n",
    ")\n",
    "copy_weights(weights)  # type: ignore\n",
    "\n",
    "lr = 1e-2\n",
    "npg_optim = npg.optim.SGD(npg_model.parameters(), lr)\n",
    "torch_optim = torch.optim.SGD(torch_model.parameters(), lr)\n",
    "\n",
    "for i in range(100):\n",
    "    npg_optim.zero_grad()\n",
    "    torch_optim.zero_grad()\n",
    "    npg_out = compute_npg(data, lbls, npg_model)\n",
    "    torch_out = compute_torch(data, lbls, torch_model)\n",
    "    npg_optim.step()\n",
    "    torch_optim.step()\n",
    "\n",
    "    if (i + 1) % 20 == 0:\n",
    "        # fmt: off\n",
    "        print(f\"\\nStep {i + 1}:\")\n",
    "        print(f\"Max out diff: {max_diff(npg_out.data, torch_out.detach().numpy())}\")\n",
    "        print(f\"Max weights data diff: {max(max_diff(a.data, t.detach().numpy()) for a, t in weights)}\")\n",
    "        print(f\"Max weights grad diff: {max(max_diff(a.grad, t.grad.numpy()) for a, t in weights)}\")\n",
    "        # fmt: on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
